{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Size\n",
    "n_rows = 1000\n",
    "n_cols = 40\n",
    "\n",
    "# Data\n",
    "X    = np.random.randn(n_rows, n_cols)\n",
    "beta = np.random.randn(n_cols, 1)\n",
    "Y    = X.dot(beta)\n",
    "\n",
    "# Covariance\n",
    "XTX = X.T.dot(X)\n",
    "XTY = X.T.dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveNQP(Q, q, epsilon, max_n_iter):\n",
    "    \n",
    "    # Initialize\n",
    "    x          = np.zeros((n_cols, 1))\n",
    "    x_diff     = np.zeros((n_cols, 1))\n",
    "    grad_f     = q.copy()\n",
    "    grad_f_bar = q.copy()\n",
    "\n",
    "    # Loop over iterations\n",
    "    for i in range(max_n_iter):\n",
    "    \n",
    "        # Get passive set information\n",
    "        passive_set = np.logical_or(x > 0, grad_f < 0)\n",
    "        n_passive = np.sum(passive_set)\n",
    "\n",
    "        # Calculate gradient\n",
    "        grad_f_bar[:] = grad_f\n",
    "        grad_f_bar[~passive_set] = 0\n",
    "        grad_norm = np.vdot(grad_f_bar, grad_f_bar)\n",
    "        \n",
    "        # Abort?\n",
    "        if (n_passive == 0 or grad_norm < epsilon):\n",
    "            break\n",
    "            \n",
    "        # Exact line search\n",
    "        alpha_den = np.vdot(grad_f_bar, Q.dot(grad_f_bar))\n",
    "        alpha = grad_norm / alpha_den\n",
    "            \n",
    "        # Update x\n",
    "        x_diff = -x.copy()\n",
    "        x -= alpha * grad_f_bar\n",
    "        x = np.maximum(x, 0.)\n",
    "        x_diff += x\n",
    "    \n",
    "        # Update gradient\n",
    "        grad_f += Q.dot(x_diff)\n",
    "        \n",
    "    # Return\n",
    "    return x\n",
    "\n",
    "\n",
    "def NNLS_GD(XTX, XTY, epsilon=1e-10, max_n_iter=100):\n",
    "\n",
    "    # Normalization factors\n",
    "    H_diag = np.diag(XTX).copy().reshape(-1,1)\n",
    "    Q_den  = np.sqrt(np.outer(H_diag, H_diag))\n",
    "    q_den  = np.sqrt(H_diag)\n",
    "\n",
    "    # Normalize\n",
    "    Q =  XTX / Q_den\n",
    "    q = -XTY.reshape(-1,1) / q_den\n",
    "    \n",
    "    # Solve NQP\n",
    "    y = solveNQP(Q, q, epsilon, max_n_iter)\n",
    "\n",
    "    # Undo normalization\n",
    "    x = y / q_den\n",
    "\n",
    "    # Return\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NNLS_CD(XTX, XTY, epsilon=1e-10, max_n_iter=100):\n",
    "    \n",
    "    # Initialize\n",
    "    x  = np.zeros((n_cols, 1))\n",
    "    f  = -XTY.reshape(-1,1)\n",
    "    mu = f.copy()\n",
    "    \n",
    "    # Loop over iterations\n",
    "    for i in range(max_n_iter):\n",
    "        \n",
    "        # Abort?\n",
    "        Hxf = XTX.dot(x) + f\n",
    "        criterion_1 = np.all(Hxf >= -epsilon)\n",
    "        criterion_2 = np.all(Hxf[x > 0] <= epsilon)\n",
    "        if (criterion_1 and criterion_2):\n",
    "            break\n",
    "    \n",
    "        # Loop over coordinates\n",
    "        for k in range(n_cols):\n",
    "            x_diff  = -x[k,0]\n",
    "            x[k,0]  = np.maximum(0., x[k,0] - mu[k,0] / XTX[k,k])\n",
    "            x_diff += x[k,0]\n",
    "            mu     += x_diff * XTX[:,k].reshape(-1,1)\n",
    "            \n",
    "    # Return\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing comparison\n",
    "- Nested python for-loop in CD is very inefficient\n",
    "- Need to port to C for a real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent algorithm:\n",
      "1000 loops, best of 3: 263 Âµs per loop\n",
      "\n",
      "\n",
      "Coordinate descent algorithm:\n",
      "100 loops, best of 3: 2.79 ms per loop\n"
     ]
    }
   ],
   "source": [
    "print (\"Gradient descent algorithm:\")\n",
    "%timeit NNLS_GD(XTX, XTY)\n",
    "print (\"\\n\")\n",
    "print (\"Coordinate descent algorithm:\")\n",
    "%timeit NNLS_CD(XTX, XTY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25767.4294909\n",
      "25767.4294909\n"
     ]
    }
   ],
   "source": [
    "def objective(X, Y, beta_hat):\n",
    "    assert np.all(beta_hat >= 0)\n",
    "    err = X.dot(beta_hat.reshape(-1,1)) - Y.reshape(-1,1)\n",
    "    return np.vdot(err, err)\n",
    "\n",
    "beta_hat_gd = NNLS_GD(XTX, XTY)\n",
    "beta_hat_cd = NNLS_GD(XTX, XTY)\n",
    "\n",
    "print (objective(X, Y, beta_hat_gd))\n",
    "print (objective(X, Y, beta_hat_cd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
